\documentclass[conference,compsoc]{IEEEtran}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{complexity}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{caption}
\DeclareCaptionLabelFormat{cont}{#1~#2\alph{ContinuedFloat}}
\captionsetup[ContinuedFloat]{labelformat=cont}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{algorithm, algorithmic}
\usepackage{lipsum}
\usetikzlibrary{backgrounds}
\setlength{\parskip}{0 em}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=blue,
}
% \urlstyle{same}

\ifCLASSOPTIONcompsoc
  % IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  \usepackage[nocompress]{cite}
  
  
\else
  % normal IEEE
  \usepackage{cite}
\fi

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
\title{An Evolutionary Approach to the Graph Bandwidth Problem}
\author{\IEEEauthorblockN{Maaz Saeed}
\IEEEauthorblockA{Dhanani School of Science\\and Engineering\\
Habib University\\
Karachi - 75290, Sindh, Pakistan\\
Email: @st.habib.edu.pk}
\and
\IEEEauthorblockN{Muhammad Usaid Rehman}
\IEEEauthorblockA{Dhanani School of Science\\and Engineering\\
Habib University\\
Karachi - 75290, Sindh, Pakistan\\
Email: mr04302@st.habib.edu.pk}
\and
\IEEEauthorblockN{Maham Shoaib Patel}
\IEEEauthorblockA{Dhanani School of Science\\and Engineering\\
Habib University\\
Karachi - 75290, Sindh, Pakistan\\
Email: mp04911@st.habib.edu.pk}}

\maketitle

\begin{abstract}
  The bandwidth problem for a graph is an NP-complete problem. Almost identical to the 
  bandwidth problem for matrices, it finds applications in sparse matrix handling, and electronic design 
  automation. It is a combinatorial optimization problem which is also NP-hard to approximate. Therefore, 
  we attempt to solve the bandwidth problem using a basic evolutionary algorithm and observe the results obtained. 
\end{abstract}
% \setlength{\parskip}{0.5 em}
\noindent \textit{\textbf{\small Keywords---}}{\small Graph Theory, Bandwidth, Graph Bandwidth, Evolutionary Algorithms}
% \setlength{\parskip}{0 em}
\IEEEpeerreviewmaketitle

\section{Introduction} 
The graph bandwidth is a well-studied problem in graph theory. It is a combinatorial optimization problem where the objective 
is to minimize the maximum distance between two vertices of a graph by finding a suitable labelling $f: V(G) \to \{1, 2, \dots, n\}$.
There are two different forms of the bandwidth problem -- the bandwidth problem for graphs and the bandwidth problem for matrices. 
Both versions of the problem are closely related since the graph version of the problem can be reduced to the matrix version using 
the adjacency matrix of the graph. 
The problem can be visualized as placing the vertices of a graph at distinct integer points along the $x$-axis so that the 
length of the longest edge is minimized. 

The inception of the matrix bandwidth problem occurred in the 1950s when structural engineers 
attempted to analyze steel frameworks by their structural matrices via computerized manipulation. The term 'bandwidth' 
was birthed as the engineers had endeavoured to discover a matrix in which all the non-zero elements 
lay withing a narrow 'band'. The inspiration for this came from operations such as 
inversion or finding determinant in as little time as possible.

In 1962, similar to this approach, L.H Harper, and A.W Hales conceived the bandwidth, 
and bandwidth sum. They used edge differences to represent single errors in a 6-bit picture code, 
in a hypercube, where it's vertices were words of the code \cite{10.2307/2946514}. Some time after this, 
R.R Kohrfage initialized his work on the graph bandwidth problem \cite{ccdg1982}. Finally, F. Harary 
published the problem, as we know it today, officially \cite{https://doi.org/10.1002/bimj.19660080427}.

\subsection{Formal Definition} \label{intro}
In more formal terms, 
the mapping $f$ is defined as $f: V(G) \to \{1, 2, \dots, n\}$, where $n = |V|$. This is also called 
a \emph{proper numbering} of the graph $G$.\cite{Lee2016} Therefore, 
we can think of these mappings as essentially labelling or numbering of the vertices. The bandwidth of a numbering $f$
is defined as:
\begin{equation}
B_f(G) = \max_{uv \in E(G)}\{|f(u) - f(v)|\}
\end{equation}

The bandwidth of the graph $G$ is given by the bandwidth of the best possible numbering:
\begin{equation}
  B(G) = \min \{B_f(G): f \; \text{is a numbering of }  G\}
\end{equation}
Bandwidths can be computed using any integer mapping, however, to make our implementation 
easier, we will be restricting ourselves to working with proper numberings only.

There exist several known mathematical bounds that relate the bandwidth of a graph 
to various graph theoretic properties. For example, it is a simple exercise to prove that 
\[B(G) = n - 1\] where $G$ is a complete graph of the form $K_n$. Similarly, there are also bounds 
relating the chromatic number and diameter with the bandwidth of the graph.  \cite{ccdg1982}

\subsection{NP-Completeness of the bandwidth problem} \label{npp}

The bandwidth problem itself is a special case of the quadratic bottleneck assignment problem, which is known to be 
$\NP$-hard. It is also known that the bandwidth problem is $\NP$-hard to approximate which makes it impossible to find 
an $O(1)$-approximation algorithm for the bandwidth problem. 

Historically, there have been endeavors to decrease (see \cite{10.1145/800195.805928}, \cite{sparse}), or minimize 
(see \cite{chen}, \cite{chen2}) 
the bandwidth of large, spares matrices, effectively, by permuting rows and columns. 
This has been translated to graph theory by Harary (see \cite{1973141}). 
Papadimitriou proved that the minimization of the bandwidth of a matrix is an 
\NP-complete problem. \cite{papadimitriou_1976}

There are several heuristic algorithms for the bandwidth problems such as the Cuthill-McKee algorithm, and the 
Gibbs-Poole-Stockmeyer algorithm. Heuristic approaches are of interest to us since they will give us an 
idea as to how we can design appropriate meta-heuristic techniques to solve the bandwidth problem. 

\section{Evolutionary Algorithms}
Evolutionary Algorithms is a term referring to a 
family of algorithms based on the evolution we see around us in nature. By mimicking learning, 
natural selection, and reproduction, we can produce solutions for various search and optimization problems. 
This concept of evolving algorithms enables us to bypass the setbacks of traditional search/optimization algorithms.

\subsection{Darwinian Evolution}
Evolutionary Algorithms are derived of a simplified Darwinian evolution. The principles of such a cycle can be as such:
\begin{enumerate}
    \item \textbf{Variation} - Individual members of a given population may have differing attributes 
    from one another, for example, physical appearance.
    \item \textbf{Inheritance} - Offspring resemble their parents to certain extents. 
    In this manner, traits are passed down from one generation to another; unrelated individuals are less likely to have common traits, as 
    compared to them with their family trees.
    \item \textbf{Selection} - Nature follows 'survival of the fittest' ideology. Individuals that 
    are better able to locate and make use of resources compared to their peers, are more likely to survive in their respective environments. 
\end{enumerate}
In accordance with these principals, results that we obtain from our algorithm may or may not resemble those of 
previous iterations. With careful manipulation of parameters, solutions produced by our code can be ranked 
higher or lower than others.
\subsection{Analogies}
Where Darwinian evolution maintains a population of individual solutions, genetic algorithms maintain 
\textit{individuals} - a population of candidate solutions \cite{Wiransky-GA}. The theory behind these 
algorithms is that solutions are produced, and improved upon, by iteratively re-producing newer generations of solutions.

The various components of an evolutionary algorithm are as follows:
\begin{enumerate}
    \item \textbf{Genotype} - In nature, genotypes are collections of genes. When two individuals procreate, a mixture of genes 
    from both, will make up the chromosomes of the offspring. In code, these \textbf{chromosomes} 
    can be expressed, for example, as strings in binary. 
    \item \textbf{Population} - Population refers to the collection of chromosomes. At any given moment, the 
    algorithm will maintain a population of individuals - candidate solutions for the problem that is being attempted 
    to be solved. In a nutshell, it is the current generation, which will be replaced by the next generation of offspring. 
    \item \textbf{Fitness Function} - a function used to evaluate individuals in a given population. Individuals 
    that produce better results, will be more favoured when it comes to selection for breeding of newer generations. As this cycle runs, 
    individuals display continuous improvement until a satisfactory solution to our problem is found, at which point we can terminate the operation.
    \item \textbf{Selection} - After individuals are evaluated and awarded a \textit{fitness value}, 
    the best among them are chosen to breed and produce the newer generation. It is important to note 
    that individuals with lower scores are still selected, but with lower probabilities, so as to not 
    cause extinction of their respective attributes.
    \item \textbf{Crossover} - refers to the mixing of chromosomes of the two parent individuals 
    that were paired in the selection process to produce two new chromosomes (offspring). This process is also known as recombination.
    \item \textbf{Mutation} - fulfills the purpose of periodically (at random; not in a set pattern) refreshing 
    the population. This introduction of new patterns in the chromosomes encourages the algorithm to search in unexplored areas, rather than 
    just exploiting what it has already chartered. The mutation may occur as random changes in chromosomes, for example, in binary string 
\end{enumerate}
\begin{figure}[h]
  \centering
  \begin{tikzpicture}[framed]
  \node[rectangle, draw=black] (A) at (0,0) {Initialization};
  \node[rectangle, draw=black] (B) at (0,-1.5) {Selection};
  \node[rectangle, draw=black] (C) at (0, -3) {Termination};
  \node[rectangle, draw=black] (D) at (3.5, -0.75) {Mutation};
  \node[rectangle, draw=black] (E) at (3.5, -2.25) {Crossover};
  \draw[-latex] (A) -- (B);
  \draw[-latex] (B) -- (C);
  \draw[-latex] (B) to[bend right=25] (E);
  \draw[-latex] (D) to[bend right=25] (B);
  \draw[-latex] (E) to[bend right=25] (D);
  \end{tikzpicture}
  \caption{Flowchart of Evolutionary Algorithms}
\end{figure}
\section{Implementation Details}
\subsection{Population Represenation}
In our implementation, an individual chromosome in our population 
is stored in the form of key-value pairs\footnote{In Python, this is implemented 
as a dictionary}, where the key is the vertex and the value is the integer label 
of the vertex. 
\setlength{\parskip}{0.4 em}

The population can be expressed as the set \[\{(v_i, f(v_i)): \; v_i \in V(G)\}\]
where $v_i$ is a vertex in graph $G$ and $f(v_i)$ is the integer label of the 
vertex. To initialize the population, we generated individuals using randomized numberings. 
Therefore, each individual is a proper numbering of the graph (see Section \ref{intro}). While storing the numberings, 
we also compute the fitness of each individual (see Section \ref{fit}) and store it along with 
each individual. 

\setlength{\parskip}{0 em}
\subsection{Fitness Function} \label{fit}
The fitness function in our implementation was derived simply from the problem. Each individual was a proper numbering 
of the graph, and therefore, each individual had a corresponding bandwidth as described in Section \ref{intro}. Therefore, 
we simply iterated over the edges of the graph and then found the maximum value. We can also say that we found 
the bandwidth $B_f(G)$ for a single numbering/ordering $f$. 

\begin{algorithm}
\caption{Fitness Function}
\begin{algorithmic}[1]
  \renewcommand{\algorithmicrequire}{\textbf{Input:}}
  \renewcommand{\algorithmicensure}{\textbf{Output:}}
  \REQUIRE A chromosome
  \ENSURE  The fitness (bandwidth) of the chromosome
  \\ \textit{Initialize edge map: }
  \STATE $A \leftarrow \{(uv): 0\} \; \; \; \forall uv \in E(G)$
  \\ \textit{Compute fitness: }
  \FOR {each $uv \in E(G)$}
  \STATE $A[uv] \leftarrow \lvert f(u) - f(v) \rvert$
  \ENDFOR
  \STATE fitness $\leftarrow \max(A)$
  \RETURN fitness 
\end{algorithmic}
\end{algorithm}

\subsection{Selection}
We implemented several different selection schema for both parent selection, and 
survivor selection. The schema we implemented were:
\begin{enumerate}
  \item \textit{Fitness-proportional Selection (FPS):} This selection scheme 
  is also called roulette-wheel selection. Parent chromosomes are selected stochastically based on 
  their fitness -- parents with a higher fitness value have a greater change of being selected. 
  Since we are doing a minimization problem, we scale the fitness values in a way that individuals with a 
  lower fitness have a higher chance of being selected.  
  \item \textit{Rank-based Selection (RBS):} In RBS, we sort the population by their fitness values and 
  create a rank ordering. The selection probabilities are determined based on ranking and not on actual 
  fitness values which can help reduce selective pressure. 
  \item \textit{Binary Tournament Selection (BT):} BT is a specific case of the more general tournament selection, 
  where a group of individuals are selected from the population and then the best individual among the sample is returned. 
  In binary tournament, two individuals are selected from the population randomly, and the more fit individual of the two 
  is returned. This reduces the selective pressure since it does not let the fittest individual dominate. 
  \item \textit{Truncation/Elitism:} In truncation, the population is ordered according to fitness values. The ranking 
  depends on the nature of the problem -- minimization or maximation -- and the individuals with the worst values 
  are truncated to maintain a given population size. 
  \item \textit{Random Selection:} In this selection scheme, parents are selected randomly 
  based on a uniform random distribution where each individual has the selection probability of 
  $\frac{1}{n_p}$ where $n_p$ is the population size. 
\end{enumerate}


\subsection{Crossover \& Mutation}
We performed a two-point crossover in order to bring genetic diversity to the 
population. All offspring was generated using the crossover operation, i.e. no offspring 
were copies of their parent chromosomes. A generic crossover 
method could not be used since the numbering had to be unique\footnote{Similar to the Travelling Salesperson Problem.}.

This method was implemented using various methods for lists and 
dictionaries that are available in 
Python. We present a pseudocode for our procedure in Algorithm \ref{algo2}.

To further maintain genetic diversity to encourage exploration of the solution space, 
we used a mutation operator. Based on a mutation probability rate that we keep 
around 0.2, we mutate our offspring chromosomes by swapping the label of two 
randomly chosen vertices. 

\begin{algorithm}
  \caption{Crossover}
  \label{algo2}
  \begin{algorithmic}[1]
    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
    \renewcommand{\algorithmicensure}{\textbf{Output:}}
    \REQUIRE Two parent chromosomes
    \ENSURE Two child chromosomes
    \STATE childA1, childA2, childB1, childB2 $\leftarrow [\;]$
    \STATE numA, numB $\leftarrow$ Extract numberings from parent chromosomes
    \STATE $a, b \leftarrow $ Randomly generate crossover points 
    \STATE $n \leftarrow |V(G)|$
    \FOR {$i \leftarrow a$ to $i \leftarrow b$}
    \STATE childA1.\textsc{Add}(numA[$i$])
    \STATE childB1.\textsc{Add}(numB[$i$])  
    \ENDFOR 
    \STATE childA2 $\leftarrow$ leftover items from numA 
    \STATE childB2 $\leftarrow$ leftover items from numB
    \STATE childA $\leftarrow$ childA2[:$a$] + childA1 + childA2[$b$:]  
    \STATE childB $\leftarrow$ childB2[:$a$] + childB1 + childB2[$b$:]
    \STATE childA $\leftarrow$ \textsc{CreateChild}(childA)
    \STATE childB $\leftarrow$ \textsc{CreateChild}(childB)
  \end{algorithmic}
\end{algorithm}


\section{Experimental Analysis}
\subsection{Testing Methods}
\subsubsection{Various Selection Schema} There are several parameters that can be 
controlled while implementing an evolutionary algorithm. 
To investigate our results and to determine which selection schema work best, 
we plotted different results by keeping some parameters constant. We kept the mutation rate, 
and the number of iterations constant. The number of generations are changing because we  We varied the parent selection strategy and the 
survivor selection strategy. For results, see Section \ref{results}.

\subsubsection{Parameter Selection}  We kept some parameter values constant to test our implementation. The constant 
values were as follows:
\begin{enumerate}
  \item \texttt{number\_of\_iterations} = 10
  \item \texttt{population\_size} = 100
  \item \texttt{offspring\_size} = 50
  \item \texttt{mutation\_rate} = 0.2 
\end{enumerate}

\subsubsection{Graphic User Interface (GUI)} To make the solution widely accessible, we developed an interface 
based on the \texttt{PyQT5} library. Our aim was to provide a user-friendly medium to run the algorithm and 
view results without having to go through extensive code.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{UI.png}
    \caption{Snippet of the program's GUI}
    \label{fig:my_label}
\end{figure}

\subsection{Results} \label{results}
We tested our algorithm on three different graphs, with 11, 23 and 100 vertices respectively. 
For the sake of brevity, we have only included results which followed an elitism (truncation) survival scheme. 
We plotted the best fitness and the average fitnesses of the algorithm against each generation 
averaged over 10 iterations. The number of generations for each plot varied slightly although it lied 
mostly in the 450-750 range due to varied convergence. We present the results here:
\setlength{\parskip}{1 em}
\newpage
\begin{center}
  \textbf{(i) Testing on 11-vertices graph:}
\end{center}
\setlength{\parskip}{0 em}
\begin{figure}[h]
  \vspace{-1 em}
  \centering 
  \begin{subfigure}{0.34\textwidth}
    \includegraphics[width=\linewidth]{../Results/_11_FPS_Truncation_100_50_450.png}
    \caption{Fitness-Proportional Selection}
  \end{subfigure}
  \begin{subfigure}{0.34\textwidth}
    \includegraphics[width=\linewidth]{../Results/_11_RBS_Truncation_100_50_700.png}
    \caption{Rank-Based Selection}
  \end{subfigure}
  \begin{subfigure}{0.34\textwidth}
    \includegraphics[width=\linewidth]{../Results/_11_BT_Truncation_100_50_700.png}
    \caption{Binary Tournament Selection}
  \end{subfigure}
  \begin{subfigure}{0.34\textwidth}
    \includegraphics[width=\linewidth]{../Results/_11_Truncation_Truncation_100_50_400.png}
    \caption{Truncation/Elitism Selection}
  \end{subfigure}
  \label{fig:graphs1}
\end{figure}
\begin{figure}\ContinuedFloat
  \centering
  \begin{subfigure}{0.34\textwidth}
    \includegraphics[width=\linewidth]{../Results/_11_Random_Truncation_100_50_700.png}
    \caption{Random Selection}
\end{subfigure}
\caption*{Figure 3: Results of EA applied to 11-vertex graph}
\label{fgigy}
\end{figure}
\newpage
\begin{center}
  \textbf{(iii) Testing on 23-vertices graph:}
\end{center}
\begin{figure}[h!]
  \centering 
  \begin{subfigure}{0.34\textwidth}
    \includegraphics[width=\linewidth]{../Results/_23_FPS_Truncation_100_50_700.png}
    \caption{Fitness-Proportional Selection}
  \end{subfigure}
  \begin{subfigure}{0.34\textwidth}
    \includegraphics[width=\linewidth]{../Results/_23_RBS_Truncation_100_50_750.png}
    \caption{Rank-Based Selection}
  \end{subfigure}
  \label{fig:graphs2}
  \begin{subfigure}{0.34\textwidth}
    \includegraphics[width=\linewidth]{../Results/_23_BT_Truncation_100_50_750.png}
    \caption{Binary Tournament Selection}
  \end{subfigure}
\end{figure}
\begin{figure}\ContinuedFloat
  \centering
  \begin{subfigure}{0.34\textwidth}
    \includegraphics[width=\linewidth]{../Results/_23_Truncation_Truncation_100_50_500.png}
    \caption{Truncation/Elitism Selection}
  \end{subfigure}
  \begin{subfigure}{0.34\textwidth}
    \includegraphics[width=\linewidth]{../Results/_23_Random_Truncation_100_50_500.png}
    \caption{Random Selection}
  \end{subfigure}
  \caption*{Figure 4: Results of EA applied to 23-vertex graph}
\end{figure}

\newpage
\begin{center}
  \textbf{(ii) Testing on 100-vertices graph:}
\end{center}
\begin{figure}[h!]
  \centering 
  \begin{subfigure}{0.34\textwidth}
    \includegraphics[width=\linewidth]{../Results/_100_FPS_Truncation_100_50_700.png}
    \caption{Fitness-Proportional Selection}
  \end{subfigure}
  \begin{subfigure}{0.34\textwidth}
    \includegraphics[width=\linewidth]{../Results/_100_RBS_Truncation_200_100_500.png}
    \caption{Rank-Based Selection}
  \end{subfigure}
\end{figure}
\begin{figure}[h!]\ContinuedFloat
  \centering
  \begin{subfigure}{0.34\textwidth}
    \includegraphics[width=\linewidth]{../Results/_100_BT_Truncation_200_100_500.png}
    \caption{Binary Tournament Selection}
  \end{subfigure}
  \begin{subfigure}{0.34\textwidth}
    \includegraphics[width=\linewidth]{../Results/_100_Truncation_Truncation_200_100_500.png}
    \caption*{Truncation/Elitism Selection}
  \end{subfigure}
  \begin{subfigure}{0.34\textwidth}
    \includegraphics[width=\linewidth]{../Results/_100_Random_Truncation_200_100_500.png}
    \caption{Random Selection}
  \end{subfigure}
  \caption*{Figure 5: Results of EA applied to 100-vertex graph}
\end{figure}

\newpage
\setlength{\parskip}{0 em}
\section{Conclusion}
Judging by the results in Section \ref{results} -- summarized in \ref{table1}, we can see that the graph bandwidth problem is not easy to solve. 
While we could obtain numberings for the graphs with 12 and 23 vertices, it was quite hard to do so with the graph with 
100 vertices. This particular graph was also dense, which made the bandwidth quite high and difficult to minimize. On the 
other hand, the problem shows promising results if the graph itself is relatively sparse. For smaller graphs, the choice of 
parent selection did not have much impact on the results. However, for larger graphs, truncation seemed to perform better.

To further improve upon and to gain more understanding regarding evolutionary approaches to the bandwidth problem, 
we suggest comparing the results of evolutionary algorithm solutions to this problem with results obtained 
from heuristic algorithms described in Section \ref{npp}, while also experimenting on different 
types of graphs and testing whether already known mathematical results regarding the bandwidth problem 
are being obeyed. Furthermore, we also plan on implementing different metaheuristics
such as Ant Colony Optimization and more sophisticated forms of evolutionary computation in order to achieve better results.      

The accompanying code for this project can be accessed at \texttt{\url{https://github.com/m-usaid/CS451-FinalProject}}. 

% % use section* for acknowledgment
\ifCLASSOPTIONcompsoc
% % The Computer Society usually uses the plural form
\section*{Acknowledgments}
\else
  % regular IEEE prefers the singular form
  \section*{Acknowledgment}
\fi

We would like to acknowledge the freely available datasets that we obtained from two different online resources. The graphs 
were obtained from \texttt{\url{https://mat.gsia.cmu.edu/COLOR/instances/}} and 
\texttt{\url{http://people.brunel.ac.uk/~mastjjb/jeb/orlib/colourinfo.html}}.

\clearpage
\begin{table}[]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|l|l|}
\hline
Vertices & Parent Selection Scheme & Survival Selection Scheme & Population & Offspring & Generations & Best Fitness & Average Fitness \\ \hline
11       & Binary Tournament       & Truncation                & 100        & 50        & 700         & 6.4          & 6.5             \\ \hline
11       & Fitness Proportionate   & Truncation                & 100        & 50        & 450         & 6.6          & 6.8             \\ \hline
11       & Rank Based              & Truncation                & 100        & 50        & 700         & 6.6          & 6.7             \\ \hline
11       & Truncation              & Truncation                & 100        & 50        & 400         & 6.8          & 6.927           \\ \hline
23       & Binary Tournament       & Truncation                & 100        & 50        & 750         & 17.0         & 17.845          \\ \hline
23       & Fitness Proportionate   & Truncation                & 100        & 50        & 700         & 17.0         & 17.317          \\ \hline
23       & Rank Based              & Truncation                & 100        & 50        & 750         & 17.5         & 18.566          \\ \hline
23       & Random                  & Truncation                & 100        & 50        & 500         & 17.3         & 18.308          \\ \hline
23       & Truncation              & Truncation                & 100        & 50        & 500         & 17.5         & 18.165          \\ \hline
100      & Binary Tournament       & Truncation                & 200        & 100       & 500         & 91.3         & 93.196          \\ \hline
100      & Rank Based              & Truncation                & 200        & 100       & 500         & 91.4         & 93.469          \\ \hline
100      & Random                  & Truncation                & 200        & 100       & 500         & 91.5         & 93.346          \\ \hline
100      & Truncation              & Truncation                & 200        & 100       & 500         & 91.5         & 93.682          \\ \hline
\end{tabular}
\end{center}
\caption{Table summarizing best and average fitness values.}
\label{table1}
\end{table}

\bibliographystyle{ieeetr}
\bibliography{refs.bib}

\end{document}
